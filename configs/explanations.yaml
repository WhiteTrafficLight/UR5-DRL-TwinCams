# explanations config
# explains all attributes and lists all options,
# this config is not meant to be run, it's for documentation only
# note: for numerical inputs only plainly written numbers are allowed, this means that scientific notation like 4e-3 is not supported
#       this is due to a quirk/bug in the PyYAML implementation

# run attributes
# these are meta attributes about how we interact with the gym env from the outside
run:
  # bool, determines whether a model is loaded
  load_model: False  
  # str, relative path of the model which is to be loaded if load_model is True
  model_path: ""    
  # attributes for training
  train:
    # int, number of parallel executions for training
    num_envs : 16  
    # int, maximum timesteps for this run
    timesteps: 15000000  
    # int, steps after which a checkpoint of the current agent is saved (this is calculated per env even when multiple ones are run in parallel, after the first env reaches this value a save will occur)
    save_freq : 30000
    # str, folder in which saved checkpoints will be stored
    save_folder: "./models/weights"  
    # str, name of the model under which it will be saved
    save_name: "PPO_default"
    # bool, whether to use a recurrent PPO model (True) or not (False)
    recurrent: False
    # int, steps until PPO updates the agent (this is per env, meaning if one env reaches this value the agent updates)
    ppo_steps: 1024  
    # int, batch size of the PPO update, note: the PPO buffer is of size num_envs * ppo_steps, so best choose batch size as a natural divisor for that number for even batches
    batch_size: 512
    # float between 0 and 1, discount factor for DRL, the higher the more the trained agent will tend to weigh future rewards  
    gamma: 0.99  
    # str, folder in which tensorboard will log data during training
    tensorboard_folder: "./models/tensorboard_logs"
    # custom policy definition using the stable_baselines3 interface
    custom_policy:
      # bool, whether to use this custom policy or not
      use: False
      # str, determines the activation function in the policy, can be "ReLU" or "tanh"  TODO: add more options
      activation_function: "ReLU"  
      # layers: 
      # directly under the layers header, write an integer for each common layer you want, the integer will be the number of neurons in that layer
      # under the value function and policy headers, write an integer for each layer you want
      # there don't need to be common layers, but both value function and policy function need at least one
      # example: the following defines a custom policy with two shared layers, a value function end with one and a policy function end with three layers
      # FYI: the standard PPO model is no common layers and both value and policy function having two layers of 64, the activation function is tanh
      layers:
        - 128
        - 128
        - value_function:
          - 64
        - policy_function:
          - 32
          - 32
          - 16
      # lstm settings
      # if you set recurrent (see above) to True, these settings govern the shape of the LSTM part of the custom network
      # if no custom policy is used, the default settings are instead hidden_size=256, n_lstm_layers=1, shared_lstm=False and enable_critic_lstm=True
      lstm:
        # int, neurons in lstm layers
        lstm_hidden_size: 512  
        # int, number of lstm layers
        n_lstm_layers: 2
        # bool, whether policy and value function parts of the policy share their lstms or each has their own
        shared_lstm: False
        # bool, whether the value function has its own lstm layers
        enable_critic_lstm: True

  # attributes for evaluation
  eval:
    # int, number of episodes for this eval run, infinitely many if -1
    max_episodes: -1  
    # int, 0: no logging at all, 1: logging into console at the end of an episode, 
    # 2: same as 1 + log for entire episode put into csv file in model/env_logs (if max_episodes is not -1 this will only happen at the end of the last episode such that the file contains all episodes)
    logging: 1 
    # float, sleep added to make movements pass slower for better visiblity (you can also use this to make the simulation run in sync with real time)
    display_delay: 0
    # bool, flags for showing visual aides like goal markings or workspace borders
    show_world_aux: True
    show_goal_aux: True
    show_sensor_aux: False

# env attributes
env:
  #   general attributes
  # int, maximum steps an episode can go on in this env
  max_steps_per_episode: 1024  
  # int, number of past episodes that are used to calculate running average stats for env performance
  stat_buffer_size: 25
  # bool, whether to normalize observations or not
  normalize_observations: False
  # bool, whether to normalize rewards or not
  normalize_rewards: False
  # engine config, governs which physics sim will power the environment
  engine:
    # str, engine name, at the moment this can be either Pybullet or Isaac
    type: "Pybullet"
    # bool, whether to use acurate physics sim for movement or not, False will result in no sim time passing and movements being instanteneous
    use_physics_sim: True
    # list of floats, determines gravity force in N in xyz world directions when using the physics sim
    gravity: [0, 0, -9.8]
    # float, time step of virtual simulated time in seconds for each env step, inverse is frame rate
    sim_step: 0.00416666666  # 1/240 s <-> 240 Hz
    # int, the amount of physics steps we run per env step, is used only when use_physics_sim is True
    # note: the lower this value, the worse the performance, but the higher the accuracy
    sim_steps_per_env_step: 1  
  
  #   robots definition
  # this section adds robots into the env, for demonstration purposes we will add every possible robot here
  robots:
    - type: "UR5" 
      config:
        # str, the name under which the robot will be run in the env, appears in logs and sensor names, make sure to give unique ones in order to avoid confusion
        name: "ur5_1"
        # floats, the xyz position where the base of the robot is mounted in the world
        base_position: [0, 0, 0]
        # floats, the orientation of the robot base w.r.t the world coordinate system, in degrees and roll-pitch-yaw format
        base_orientation: [0, 0, 90]
        # list of floats, the resting angles in degrees of the robot's joints a.k.a. its default pose, must be the same amount as the (movable) joints of the robot
        # if the scenario does not define a starting pose for the robot this will also be the pose in which the robot will start each env episode
        resting_angles: [-180, -45, -90, -135, 90, 0]
        # int, determines the way in which the robot will be controlled by the agent, possible values: 0: inverse kinematics, 1: joint angles, 2: joint velocities
        control_mode: 2
        # float, determines the maximum xyz movement when using inverse kinematics
        xyz_delta: 0.005
        # float, determines the maximum rpy movement when using inverse kinematics
        rpy_delta: 0.005

      #   sensor definition
      # here we define all the sensors that are bound to this specific robot
      # for illustration purposes, this robot will have all availabe sensors at once (with the exception of sensors that belong to a robot but need another robot as reference, the examples for that are further below with the second example robot)
      # note: any robot will by default have a position/rotation sensor for its end effector and a joints sensor
      # you can however define position sensors for other parts of the robot here
      sensors:
        - type: "PositionRotation"  # sensor type that reports position and orientation of a robot link
          config:
            # int, every x steps the sensor will update its data, higher values get more fps for the simulation but lower accuracy
            update_steps: 1
            # whether this sensor's output will be added to the observation space
            add_to_observation_space: True
            # whether this sensor's logging data will be collected
            add_to_logging: True

            # sensor type specific instructions
            # int, link id for which the position and rotation are to be reported
            link_id: 6
            # bool, whether to report rotation as quaternion (True) or rpy (False)
            quaternion: True
        - type: "LidarSensorUR5"  # sensor that sends rays and reports the result
          config:
            update_steps: 1
            normalize: False
            add_to_observation_space: True
            add_to_logging: True

            # sensor type specific instructions
            # int, amount of values that the lidar indicator is able to report, the higher this value the finer the resolution of the raw lidar data
            indicator_buckets: 6
            # float, offset of the lidar rays from mesh center they're starting from
            ray_start: 0
            # float, end of the lidar as measured from the mesh center, ray length = this - ray_start
            ray_end: 0.3
            ray_setup:
              # the keys here are all the robot links equppid with lidar rays
              # you can remove ones you don't want to have
              # the first number is the amount of directions, the second is the number of rays per direction (see class implementation for details on what these numbers mean exactly)
              ee_forward: [1, 1]
              wrist3_circle: [10, 10]
              wrist2_circle: [10, 10]
              wrist1_circle: [10, 10]
              upper_arm: [10, 10]
            # bool, whether the output will report the indicator or raw measured distances
            indicator: True
        - type: "Obstacle"  # sensor that uses an engine call to report the relative position of the nearest obstacles
          config:
            update_steps: 1
            add_to_observation_space: True
            add_to_logging: False

            # sensor type specific instructions
            # int, the number of obstacles that this sensor reports on
            num_obstacles: 2
            # float, max distance in which to pick up obstacles in, if there are fewer in this radius than num_obstacles a generic output will be reported instead
            max_distance: 15
            # int, link id for which the distance mesaures will be given
            reference_link_id: 7
        - type: "OnBodyCameraUR5"  # a camera mounted on the robot end effector
          config:
            update_steps: 1
            normalize: False
            add_to_observation_space: True
            add_to_logging: True

            # sensor type specific instructions
            camera_args:
              # str, camera name
              name: "OnBody_ur5_1"
              # int, image height
              height: 128
              # int, image width
              width: 128
              # str, camera type, can be "grayscale", "rgb" or "rgbd"
              type: "grayscale"
              # floats, up vector of the camera
              up_vector: [0, 0, 1]
              # float, field of view of the camera in degrees
              fov: 60
              # float, aspect ratio of the camera
              aspect_ratio: 1
              # float, distance of the near plane of the camera
              near_val: 0.05
              # float, distance of the far plane of the camera
              far_val: 5
            # floats, relative position of the camera w.r.t. to the robot's end effector, can also be empty (results in a default positioning)
            position_relative_to_effector: []
        - type: "StaticFloatingCameraFollowEffector"  # a camera floating in free space but always centered on the robot's end effector
          config:
            update_steps: 1
            normalize: False
            add_to_observation_space: True
            add_to_logging: True
            name: "EEFollow_ur5_1"
            camera_args:
              height: 128
              width: 128
              type: "grayscale"
              up_vector: [0, 0, 1]
              fov: 60
              aspect_ratio: 1
              near_val: 0.05
              far_val: 5
            # floats, position of the camera in world space
            position: [2, 2, 1.5]

      #   goal definition
      # here we define the goal that this roboter is supposed to pursue
      # each robot can only have one goal at a time
      # a robot can also have no goal at all, but at least one robot in the env must have a goal
      # there are a few scenarios that rely on the first robot being the main one, so it's best practice to put the robot with the goal (in case there are others without one) first
      goal:
        type: "PositionCollision"  # a goal for reaching a position without colliding
        config:
          # bool, whether this goal's logging data is collected
          add_to_logging: True
          # bool, whether the robot can continue to do things or be frozen if it achieved success (only relevant if there are other robots with goals in the env)
          continue_after_success: True
          
          # goal type specific settings
          # float, reward given for reaching the position goal
          reward_success: 10
          # float, reward given for collision
          reward_collision: -5
          # float, multiplier for the reward given for distance to goal position
          reward_distance_mult: -0.01
          # float, initial distance threshold for position success
          dist_threshold_start: 0.2
          # float, final distance threshold for position success, also used when in env is in eval mode
          dist_threshold_end : 0.01
          # float, increment that is subtracted from current distance threshold when the threshold is high and env success rate is above 80%
          dist_threshold_increment_start: 0.01
          # float, increment that is subtracted from current distance threshold when the threshold is small and env success rate is above 80%
          dist_threshold_increment_end: 0.001
          # float, overwrite for the start of the distance threshold, works for both train and eval, useful for resuming training, does nothing if empty
          dist_threshold_overwrite: 

    - type: "KR16" 
      name: "kr16_1"
      config:
        base_position: [0, 0, 0]
        base_orientation: [0, 0, 90]
        resting_angles: [-180, -45, -90, -135, 90, 0]
        control_mode: 2
        xyz_delta: 0.005
        rpy_delta: 0.005

      #   sensor definition
      # for this robot we show all examples of robot-bound sensors that need another robot
      # sensors of this type need another robot as reference
      # therefore, robots with this sensor must ALWAYS be mentioned after the robot which this sensor is focusing on
      sensors:
        - type: "BuddyRobotCamera" 
          config: 
            update_steps: 1
            normalize: False
            add_to_observation_space: True
            add_to_logging: True
            name: "BuddyCam_generated_1"
            camera_args:
              height: 128
              width: 128
              type: "grayscale"
              up_vector: [0, 0, 1]
              fov: 60
              aspect_ratio: 1
              near_val: 0.05
              far_val: 5
            # str or floats, robot or position in world space to focus on
            # if str, must be the name of a robot that was mentioned above this one in the config
            target: "ur5_1"

  #   sensor definition
  # here we will define all sensors that are not bound (in some way or another) to a robot, e.g. free floating cameras
  # for illustration purposes, we will add all possible types of non-robot bound sensors
  sensors:
    - type: "StaticFloatingCamera"
      config:
        update_steps: 1
        normalize: False
        add_to_observation_space: True
        add_to_logging: True
        name: "free_floating_1"
        camera_args:
          height: 128
          width: 128
          type: "grayscale"
          up_vector: [0, 0, 1]
          fov: 60
          aspect_ratio: 1
          near_val: 0.05
          far_val: 5
        position: [-2, -2, 1.5]
    
  world:
    type: "RandomObstacle"
    config:
      # floats, workspace boundaries in the following format: xmin, xmax, ymin, ymax, zmin, zmax
      workspace_boundaries: [-0.4, 0.4, 0.3, 0.7, 0.2, 0.5]
      
      # type specific settings
      # int, number of static obstacles
      num_static_obstacles: 3
      # int, number of moving obstacles
      num_moving_obstacles: 1
      # floats, measurements of the three dimensions for random box obstacles
      # format: widthmin, widthmax, lengthmin, lengthmax, heightmin, heightmax
      box_measurements: [0.025, 0.075, 0.025, 0.075, 0.00075, 0.00125]
      # floats, size of the random radii of sphere obstacles, format: rmin, rmax
      sphere_measurements: [0.005, 0.02]
      # floats, bounds for the random velocities of the moving obstacles, format: vmin, vmax
      moving_obstacles_vels: [0.5, 2]
      # lists of floats, directions for the moving obstacles, must either be the same length as num_moving_obstacles or empty (in which case directions will be generated randomly)
      moving_obstacles_directions: []
      # floats, bounds for the random trajectory lengths of the moving obstacles, format: tmin, tmax
      moving_obstacles_trajectory_length: [0.05, 0.75]